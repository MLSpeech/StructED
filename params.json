{"name":"StructED","tagline":"Structured Prediction Package written in Java","body":"README\r\n======\r\n\r\nStructED 1.0.0\r\n\r\nCopyright (C) Adiyoss\r\n\r\nStructED is a collection of machine learning algorithms for structured prediction problems. In structured prediction each task is distinctive and has its own set of feature functions, unique measure of performance and in many cases a non-standard inference. StructED package was designed to handle this inherent implementation complexity by having an easy interface to user-defined feature functions, decoder and evaluation function. The package is a general framework for implementation structured prediction problems and algorithms, and it is highly customizable. All algorithms are implemented by the same interfaces, so adding new algorithms or comparing them is straightforward. The library is written in Java, hence platform independent, and is available at http://adiyoss.github.io/StructED/ \r\n\r\nKeywords: Machine Learning, Structured Prediction, SVM, Direct Loss, CRF, Ramp Loss, Probit Loss, Passive Aggressive, RankSVM\r\n\r\n\r\nHOW TO USE\r\n======\r\nAll the source code for StructED is availabe to download from this reposetory. To use StructED in your own project you should download the code and implement three interfaces that are task dependent to your problem, the TaskLoss interface with is responsiable for the loss/cost function, the Prediction interface which is responsiable for the inferences (argmax, argmax+loss) and the PhiConvertor interface which is responsiable for the feature functions/feature maps.\r\n\r\nVery detaild tutorial about adding new task to StructED can be found under the docs/ directory.\r\n\r\nCONFIG FILE - TRAIN\r\n======\r\n\r\nTo run StructED (Train or Predict), one should supply a congfig file. The file should be from the following format: \r\n(All the parameters in the config file should be as follows: parameter type, colon(:), parameter value)\r\n\r\nGENERAL PARAMETERS\r\n=====\r\n\t\r\n - train_path: the path to the training set data - Mandatory \r\n - w_output: the path to save the weights vector (model)\t\r\n - type: the algorithm type - Mandatory\r\n \t- 0 - Passive Aggressive\r\n \t- 1 - SVM\r\n \t- 2 - Direct Loss\r\n \t- 3 - CRF\r\n \t- 4 - Ramp Loss\r\n \t- 5 - Probit Loss\r\n - task: the cost/loss function number - Mandatory\r\n - epoch: the number of epochs on the data - Mandatory\r\n - task_param: cost/loss parameters if needed, can store multiple parameters splited by (;) - optional\r\n - kernel: kernel type, and parameters(i.e sigma) - Optional\r\n \t- 0 - poly 2 degree\r\n\t- 1 - 2nd taylor approximation for RBF - setting the sigma value can be done like that: kernel:1:19\r\n\t- 2 - 3nd taylor approximation for RBF - setting the sigma value can be done like that: kernel:2:19\r\n - init_w: the path for the initial weights - Optional\r\n - phi: feature function type - Mandatory\r\n - prediction: prediction function, should implement also the loss-augmented function - Mandatory\r\n - reader: db reader type - Mandatory\r\n - writer: db writer type - Mandatory\r\n\t- for both reader and writer\r\n\t\t- use 0 for standard reader(like mnist db or the dummy data)\r\n - isAvg: boolean that indicates whether to average the weights vector - optional, default is 0\r\n - size_of_vector: size of vector after the feature mapping functions - Mandatory\r\n\r\nSPECIFIC - ALGORITHM DEPENDENT\r\n===\r\n\r\n## Passive Aggressive\r\n\r\n - c: parameter for the PA algorithm\t\t\t\t\r\n\r\n## SVM\r\n\r\n - lambda: lambda parameter for the SVM\t\t\t\t\t\t\r\n - eta: learning rate\r\n\t\t\t    \r\n\r\n## Direct Loss\r\n\r\n - eta: learning rate\r\n - epsilon: epsilon parameter for the DL\t   \r\n\t\t\t\t\t\t  \r\n\r\n## CRF\t\r\n\r\n - eta: learning rate\r\n - lambda: lambda parameter for the CRF\r\n\r\n## Ramp Loss\t\r\n\r\n - eta:\tlearning rate\r\n - lambda: lambda parameter for the RL\t\t\t\t  \t\t\t\r\n\r\n## Probit Loss\r\n\r\n - eta:\tlearning rate\r\n - lambda: lambda parameter for the PL\t\r\n - num_of_iteration: the number of times to generation noise for the weights vector\r\n\r\n\r\nCONFIG FILE - PREDICT\r\n======\r\n\r\n - test_path: the path to the test set data - Mandatory \r\n - output_file: the path to output the scores file - Mandatory\r\n - w_path: the path to the weights vector (model) - Mandatory \r\n - examples_2_display: how many examples to display in the scores file - Mandatory\r\n - task: the loss(cost) function, the same as the train - Mandatory\r\n - task_param: task loss parameters if needed\r\n - kernel: kernel type, and parameters(i.e sigma) - Optional\r\n \t- 0 - poly 2 degree\r\n\t- 1 - RBF 2nd taylor approximation - setting the sigma value can be done like that: kernel:1:19\r\n\t- 2 - RBF 3nd taylor approximation - setting the sigma value can be done like that: kernel:2:19\r\n - phi: feature function type - Mandatory\r\n - prediction: prediction function, should implement the inferences - Mandatory\r\n - reader: reader type - Mandatory\r\n - writer: writer type - Mandatory\r\n\t- for both reader and writer\r\n\t\t- use 0 for standard reader(like mnist db or the dummy data)\r\n - size_of_vector: size of vector after the feature mapping functions - Mandatory\r\n\r\nExamples\r\n========\r\nInside StructED package you can find implementations to three tasks:\r\n - Dummy data\r\n - MNIST dataset (multi-class problem)\r\n - Vowel Duration Measurement\r\n\r\nFor each task we supplied all the relevent classes, task-loss, prediction and feature functions, all of them can be found under the src/ directory.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}